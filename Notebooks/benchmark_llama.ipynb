{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the benchmarker over our stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial setups and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"..\"))\n",
    "\n",
    "# Presuming your directory structure is the default git one, this is set up to run in the main web-agent folder, so cd up one:\n",
    "if \"src\" not in os.listdir():\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "load_dotenv()\n",
    "nest_asyncio.apply() # to allow asynchronous calls in a jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now imports that are more specific to our project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents import WebAgent\n",
    "from langchain_groq import ChatGroq\n",
    "from src.omniparser import OmniParserConfig, OmniParser\n",
    "from tests.benchmark_agent_node import select_examples, compare_agent_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m config \u001b[38;5;241m=\u001b[39m OmniParserConfig(\n\u001b[1;32m      2\u001b[0m     som_model_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m      3\u001b[0m         project_root, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124momniparser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124micon_detect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m omniparser \u001b[38;5;241m=\u001b[39m \u001b[43mOmniParser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# if you want to use llava, set OmniParserConfig to have caption_model=\"llava\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m web_agent \u001b[38;5;241m=\u001b[39m WebAgent(project_root\u001b[38;5;241m=\u001b[39mproject_root, image_parser\u001b[38;5;241m=\u001b[39momniparser, log_screenshots\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, tag_with_js\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# have to set llm if we don't want llama\u001b[39;00m\n",
      "File \u001b[0;32m~/web-agent/src/omniparser.py:371\u001b[0m, in \u001b[0;36mOmniParser.from_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03mClass method to initialize an OmniParser instance using an OmniParserConfig instance.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m    OmniParser: A new instance of OmniParser initialized with the specified configuration.\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# Initialize the OCRReader, SOMModel, and CaptionModelProcessor based on the config\u001b[39;00m\n\u001b[0;32m--> 371\u001b[0m ocr_reader \u001b[38;5;241m=\u001b[39m \u001b[43mOCRReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m som_model \u001b[38;5;241m=\u001b[39m SOMModel(config\u001b[38;5;241m.\u001b[39msom_model_path)\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mcaption_model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblip2\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/web-agent/src/omniparser.py:55\u001b[0m, in \u001b[0;36mOCRReader.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/easyocr/easyocr.py:92\u001b[0m, in \u001b[0;36mReader.__init__\u001b[0;34m(self, lang_list, gpu, model_storage_directory, user_network_directory, detect_network, recog_network, download_enabled, detector, recognizer, verbose, quantize, cudnn_benchmark)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcudnn_benchmark\u001b[38;5;241m=\u001b[39mcudnn_benchmark\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detector:\n\u001b[0;32m---> 92\u001b[0m     detector_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetDetectorPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetect_network\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# recognition model\u001b[39;00m\n\u001b[1;32m     95\u001b[0m separator_list \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/easyocr/easyocr.py:256\u001b[0m, in \u001b[0;36mReader.getDetectorPath\u001b[0;34m(self, detect_network)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m calculate_md5(detector_path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetection_models[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetect_network][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmd5sum\u001b[39m\u001b[38;5;124m'\u001b[39m], corrupt_msg\n\u001b[1;32m    255\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDownload complete\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mcalculate_md5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetector_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetection_models[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetect_network][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmd5sum\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_enabled:\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMD5 mismatch for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m and downloads disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m detector_path)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/easyocr/utils.py:636\u001b[0m, in \u001b[0;36mcalculate_md5\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m    634\u001b[0m hash_md5 \u001b[38;5;241m=\u001b[39m hashlib\u001b[38;5;241m.\u001b[39mmd5()\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 636\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m: f\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m4096\u001b[39m), \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    637\u001b[0m         hash_md5\u001b[38;5;241m.\u001b[39mupdate(chunk)\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hash_md5\u001b[38;5;241m.\u001b[39mhexdigest()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/easyocr/utils.py:636\u001b[0m, in \u001b[0;36mcalculate_md5.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    634\u001b[0m hash_md5 \u001b[38;5;241m=\u001b[39m hashlib\u001b[38;5;241m.\u001b[39mmd5()\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 636\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    637\u001b[0m         hash_md5\u001b[38;5;241m.\u001b[39mupdate(chunk)\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hash_md5\u001b[38;5;241m.\u001b[39mhexdigest()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = OmniParserConfig(\n",
    "    som_model_path=os.path.join(\n",
    "        project_root, \"src\", \"weights\", \"omniparser\", \"icon_detect\", \"best.pt\"\n",
    "    ),\n",
    "    device=\"cuda\",\n",
    "    caption_model_path=os.path.join(\n",
    "        project_root, \"src\", \"weights\", \"omniparser\", \"icon_caption_blip2\"\n",
    "    )\n",
    ")\n",
    "omniparser = OmniParser.from_config(config)  # if you want to use llava, set OmniParserConfig to have caption_model=\"llava\"\n",
    "web_agent = WebAgent(project_root=project_root, image_parser=omniparser, log_screenshots=False, tag_with_js=False)  # have to set llm if we don't want llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Found 7 examples\n",
      "INFO: Found 2 examples\n",
      "INFO: Found 11 examples\n",
      "INFO: Found 5 examples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Found 9 examples\n",
      "INFO: Found 4 examples\n",
      "INFO: Found 1 examples\n",
      "INFO: Found 4 examples\n",
      "INFO: Found 3 examples\n",
      "\n",
      "0: 736x1280 2 icons, 56.6ms\n",
      "Speed: 4.6ms preprocess, 56.6ms inference, 466.7ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:47:46,141: INFO: logger: Step 1 | Action: Click | Action Args: [16]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 6 icons, 6.4ms\n",
      "Speed: 3.1ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding inputs for image tokens in BLIP-2 should be done in processing. Please follow instruction here (https://gist.github.com/zucchini-nlp/e9f20b054fa322f84ac9311d9ab67042) to update your BLIP-2 model. Using processors without these attributes in the config is deprecated and will throw an error in v4.50.\n",
      "[2024-12-19 23:47:50,157: INFO: logger: Step 2 | Action: Google | Action Args: None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 (no detections), 6.9ms\n",
      "Speed: 3.1ms preprocess, 6.9ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 (no detections), 6.9ms\n",
      "Speed: 3.0ms preprocess, 6.9ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 (no detections), 6.9ms\n",
      "Speed: 2.9ms preprocess, 6.9ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 11 icons, 6.4ms\n",
      "Speed: 3.1ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:48:02,432: INFO: logger: Step 4 | Action: None | Action Args: None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 12 icons, 6.6ms\n",
      "Speed: 3.2ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:48:05,927: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 5.000000 seconds]\n",
      "[2024-12-19 23:48:11,640: INFO: logger: Step 5 | Action: Click | Action Args: [0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 11 icons, 6.4ms\n",
      "Speed: 3.0ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:48:13,676: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 9.000000 seconds]\n",
      "[2024-12-19 23:48:24,210: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-19 23:48:32,206: INFO: logger: Step 6 | Action: Type | Action Args: [39, '85000']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 19 icons, 6.4ms\n",
      "Speed: 3.1ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:48:34,112: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 11.000000 seconds]\n",
      "[2024-12-19 23:48:46,402: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-19 23:48:53,942: INFO: logger: Step 7 | Action: Click | Action Args: [75]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 24 icons, 6.6ms\n",
      "Speed: 3.1ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:48:57,884: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 9.000000 seconds]\n",
      "[2024-12-19 23:49:07,935: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 5.000000 seconds]\n",
      "[2024-12-19 23:49:13,566: INFO: logger: Step 1 | Action: Type | Action Args: [13, 'Mortgage rates California']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 15 icons, 6.8ms\n",
      "Speed: 3.3ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:49:17,330: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 8.000000 seconds]\n",
      "[2024-12-19 23:49:27,025: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 6.000000 seconds]\n",
      "[2024-12-19 23:49:33,744: INFO: logger: Step 2 | Action: Click | Action Args: [42]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 7 icons, 6.6ms\n",
      "Speed: 3.2ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:49:35,346: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 8.000000 seconds]\n",
      "[2024-12-19 23:49:44,589: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 6.000000 seconds]\n",
      "[2024-12-19 23:49:51,377: INFO: logger: Step 1 | Action: Click | Action Args: [20]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 8 icons, 6.9ms\n",
      "Speed: 3.3ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:49:53,290: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 8.000000 seconds]\n",
      "[2024-12-19 23:50:03,205: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 5.000000 seconds]\n",
      "[2024-12-19 23:50:08,862: INFO: logger: Step 2 | Action: Click | Action Args: [20]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 13 icons, 6.7ms\n",
      "Speed: 3.3ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:50:10,266: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 8.000000 seconds]\n",
      "[2024-12-19 23:50:20,174: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-19 23:50:28,731: INFO: logger: Step 3 | Action: Type | Action Args: [8, 'Delhi']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 14 icons, 7.3ms\n",
      "Speed: 3.7ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:50:30,094: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 9.000000 seconds]\n",
      "[2024-12-19 23:50:42,539: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 10.000000 seconds]\n",
      "[2024-12-19 23:50:53,303: INFO: logger: Step 4 | Action: Click | Action Args: [0, 'Search flights']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 15 icons, 6.4ms\n",
      "Speed: 3.2ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:50:54,789: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 9.000000 seconds]\n",
      "[2024-12-19 23:51:05,894: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-19 23:51:14,925: INFO: logger: Step 5 | Action: None | Action Args: None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"thoughts\": \"Based on the screenshot, I can see that there are several text boxes and buttons on the page. The objective is to find the best flight tickets from Delhi to San Francisco on 21st December. * I need to enter the departure and arrival airports in the respective text boxes. * I need to select the date of travel, which is 21st December. * I need to click the 'Search flights' button to initiate the search.\",\n",
      "    \"action\": \"Type\",\n",
      "    \"args\": [9, \"DEL\"]\n",
      "}\n",
      "{\n",
      "    \"thoughts\": \"Based on the screenshot, I can see that there are several text boxes and buttons on the page. The objective is to find the best flight tickets from Delhi to San Francisco on 21st December. * I need to enter the departure and arrival airports in the respective text boxes. * I need to select the date of travel, which is 21st December. * I need to click the 'Search flights' button to initiate the search.\",\n",
      "    \"action\": \"Type\",\n",
      "    \"args\": [10, \"San Francisco\"]\n",
      "}\n",
      "{\n",
      "    \"thoughts\": \"Based on the screenshot, I can see that there are several text boxes and buttons on the page. The objective is to find the best flight tickets from Delhi to San Francisco on 21st December. * I need to enter the departure and arrival airports in the respective text boxes. * I need to select the date of travel, which is 21st December. * I need to click the 'Search flights' button to initiate the search.\",\n",
      "    \"action\": \"Type\",\n",
      "    \"args\": [12, \"21st December\"]\n",
      "}\n",
      "{\n",
      "    \"thoughts\": \"Based on the screenshot, I can see that there are several text boxes and buttons on the page. The objective is to find the best flight tickets from Delhi to San Francisco on 21st December. * I need to enter the departure and arrival airports in the respective text boxes. * I need to select the date of travel, which is 21st December. * I need to click the 'Search flights' button to initiate the search.\",\n",
      "    \"action\": \"Click\",\n",
      "    \"args\": [0]\n",
      "}\n",
      "\n",
      "0: 736x1280 15 icons, 7.0ms\n",
      "Speed: 3.3ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:51:16,303: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 10.000000 seconds]\n",
      "[2024-12-19 23:51:27,891: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 6.000000 seconds]\n",
      "[2024-12-19 23:51:34,720: INFO: logger: Step 6 | Action: Click | Action Args: [13]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 56 icons, 6.9ms\n",
      "Speed: 3.0ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:51:40,944: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 6.000000 seconds]\n",
      "[2024-12-19 23:51:47,967: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-19 23:51:55,898: INFO: logger: Step 7 | Action: None | Action Args: None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 53 icons, 6.9ms\n",
      "Speed: 3.3ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:52:01,866: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 5.000000 seconds]\n",
      "[2024-12-19 23:52:08,628: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 10.000000 seconds]\n",
      "[2024-12-19 23:52:19,417: INFO: logger: Step 8 | Action: Click | Action Args: [0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 18 icons, 6.6ms\n",
      "Speed: 3.1ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:52:21,250: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 8.000000 seconds]\n",
      "[2024-12-19 23:52:30,804: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-19 23:52:38,910: INFO: logger: Step 9 | Action: Google | Action Args: None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 5 icons, 7.1ms\n",
      "Speed: 3.2ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:52:40,877: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 9.000000 seconds]\n",
      "[2024-12-19 23:52:51,441: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-19 23:52:59,989: INFO: logger: Step 10 | Action: GoBack | Action Args: None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 5 icons, 10.1ms\n",
      "Speed: 4.0ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:53:01,619: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 10.000000 seconds]\n",
      "[2024-12-19 23:53:13,344: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 6.000000 seconds]\n",
      "[2024-12-19 23:53:20,424: INFO: logger: Step 11 | Action: Click | Action Args: [5]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 17 icons, 6.9ms\n",
      "Speed: 3.1ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:53:23,498: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-19 23:53:32,030: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-19 23:53:39,796: INFO: logger: Step 1 | Action: Type | Action Args: [2, 'non-alcoholic eggnog recipe']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 8 icons, 6.7ms\n",
      "Speed: 3.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:53:41,619: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-19 23:53:50,077: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 5.000000 seconds]\n",
      "[2024-12-19 23:53:56,025: INFO: logger: Step 3 | Action: Click | Action Args: [21]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 3 icons, 7.1ms\n",
      "Speed: 3.4ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:53:57,626: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 6.000000 seconds]\n",
      "[2024-12-19 23:54:04,803: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 4.000000 seconds]\n",
      "[2024-12-19 23:54:09,326: INFO: logger: Step 4 | Action: Google | Action Args: None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 17 icons, 6.6ms\n",
      "Speed: 3.0ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:54:13,048: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-19 23:54:21,247: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 6.000000 seconds]\n",
      "[2024-12-19 23:54:28,138: INFO: logger: Step 5 | Action: Click | Action Args: [18]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 3 icons, 7.0ms\n",
      "Speed: 3.3ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:54:30,254: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-19 23:54:38,738: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-19 23:54:46,935: INFO: logger: Step 6 | Action: Click | Action Args: [27]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 7 icons, 6.6ms\n",
      "Speed: 3.1ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:54:48,514: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 9.000000 seconds]\n",
      "[2024-12-19 23:54:58,849: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 6.000000 seconds]\n",
      "[2024-12-19 23:55:05,818: INFO: logger: Step 1 | Action: Click | Action Args: [20]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 8 icons, 6.8ms\n",
      "Speed: 3.3ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:55:07,739: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-19 23:55:16,731: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 8.000000 seconds]\n",
      "[2024-12-19 23:55:27,020: INFO: logger: Step 2 | Action: None | Action Args: None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 59 icons, 6.8ms\n",
      "Speed: 3.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:55:32,123: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 6.000000 seconds]\n",
      "[2024-12-19 23:55:39,604: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-19 23:55:47,422: INFO: logger: Step 3 | Action: Click | Action Args: [7]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 55 icons, 6.9ms\n",
      "Speed: 3.4ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:55:52,197: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-19 23:56:01,006: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 8.000000 seconds]\n",
      "[2024-12-19 23:56:09,823: INFO: logger: Step 4 | Action: Type | Action Args: [8, 'DEL', 9, 'DXB', 10, 20, 11, 25]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 21 icons, 6.7ms\n",
      "Speed: 3.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:56:11,976: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 9.000000 seconds]\n",
      "[2024-12-19 23:56:23,597: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-19 23:56:31,314: INFO: logger: Step 5 | Action: Click | Action Args: [0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 21 icons, 6.9ms\n",
      "Speed: 3.3ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:56:32,849: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 8.000000 seconds]\n",
      "[2024-12-19 23:56:42,111: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 6.000000 seconds]\n",
      "[2024-12-19 23:56:48,780: INFO: logger: Step 6 | Action: Click | Action Args: [0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 47 icons, 6.7ms\n",
      "Speed: 3.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:56:53,413: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 8.000000 seconds]\n",
      "[2024-12-19 23:57:03,293: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 8.000000 seconds]\n",
      "[2024-12-19 23:57:12,546: INFO: logger: Step 7 | Action: Type | Action Args: [14, '20 Dec 24']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 16 icons, 7.1ms\n",
      "Speed: 3.1ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:57:14,589: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 8.000000 seconds]\n",
      "[2024-12-19 23:57:24,996: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 8.000000 seconds]\n",
      "[2024-12-19 23:57:37,545: INFO: logger: Step 8 | Action: None | Action Args: None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"thoughts\": \"* The objective is to find the best flight from Delhi to Dubai on 20th December and returning on 25th December.\\n* The bounding boxes provided are mostly text-based, with some icons.\\n* The search flights button is present in the bounding boxes, but it's not clear if it's the correct one to use.\\n* There are multiple departure and arrival airport options, but no clear indication of which one to choose.\\n* The dates are also present, but it's not clear how to select the correct dates.\\n* There are no clear options for selecting the number of passengers or class of travel.\",\n",
      "    \"action\": \"Type\",\n",
      "    \"args\": [9, \"Delhi\"]\n",
      "}\n",
      "{\n",
      "    \"thoughts\": \"* The objective is to find the best flight from Delhi to Dubai on 20th December and returning on 25th December.\\n* The bounding boxes provided are mostly text-based, with some icons.\\n* The search flights button is present in the bounding boxes, but it's not clear if it's the correct one to use.\\n* There are multiple departure and arrival airport options, but no clear indication of which one to choose.\\n* The dates are also present, but it's not clear how to select the correct dates.\\n* There are no clear options for selecting the number of passengers or class of travel.\",\n",
      "    \"action\": \"Type\",\n",
      "    \"args\": [10, \"Dubai\"]\n",
      "}\n",
      "{\n",
      "    \"thoughts\": \"* The objective is to find the best flight from Delhi to Dubai on 20th December and returning on 25th December.\\n* The bounding boxes provided are mostly text-based, with some icons.\\n* The search flights button is present in the bounding boxes, but it's not clear if it's the correct one to use.\\n* There are multiple departure and arrival airport options, but no clear indication of which one to choose.\\n* The dates are also present, but it's not clear how to select the correct dates.\\n* There are no clear options for selecting the number of passengers or class of travel.\",\n",
      "    \"action\": \"Type\",\n",
      "    \"args\": [11, \"20\"]\n",
      "}\n",
      "{\n",
      "    \"thoughts\": \"* The objective is to find the best flight from Delhi to Dubai on 20th December and returning on 25th December.\\n* The bounding boxes provided are mostly text-based, with some icons.\\n* The search flights button is present in the bounding boxes, but it's not clear if it's the correct one to use.\\n* There are multiple departure and arrival airport options, but no clear indication of which one to choose.\\n* The dates are also present, but it's not clear how to select the correct dates.\\n* There are no clear options for selecting the number of passengers or class of travel.\",\n",
      "    \"action\": \"Type\",\n",
      "    \"args\": [12, \"25\"]\n",
      "}\n",
      "{\n",
      "    \"thoughts\": \"* The objective is to find the best flight from Delhi to Dubai on 20th December and returning on 25th December.\\n* The bounding boxes provided are mostly text-based, with some icons.\\n* The search flights button is present in the bounding boxes, but it's not clear if it's the correct one to use.\\n* There are multiple departure and arrival airport options, but no clear indication of which one to choose.\\n* The dates are also present, but it's not clear how to select the correct dates.\\n* There are no clear options for selecting the number of passengers or class of travel.\",\n",
      "    \"action\": \"Click\",\n",
      "    \"args\": [19]\n",
      "}\n",
      "{\n",
      "    \"thoughts\": \"* The objective is to find the best flight from Delhi to Dubai on 20th December and returning on 25th December.\\n* The bounding boxes provided are mostly text-based, with some icons.\\n* The search flights button is present in the bounding boxes, but it's not clear if it's the correct one to use.\\n* There are multiple departure and arrival airport options, but no clear indication of which one to choose.\\n* The dates are also present, but it's not clear how to select the correct dates.\\n* There are no clear options for selecting the number of passengers or class of travel.\",\n",
      "    \"action\": \"Click\",\n",
      "    \"args\": [20]\n",
      "}\n",
      "\n",
      "0: 736x1280 5 icons, 6.8ms\n",
      "Speed: 3.3ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:57:39,098: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 12.000000 seconds]\n",
      "[2024-12-19 23:57:52,784: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 6.000000 seconds]\n",
      "[2024-12-19 23:57:59,698: INFO: logger: Step 9 | Action: Click | Action Args: [2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 6 icons, 7.1ms\n",
      "Speed: 3.0ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:58:01,491: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-19 23:58:09,848: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 5.000000 seconds]\n",
      "[2024-12-19 23:58:16,087: INFO: logger: Step 1 | Action: Type | Action Args: [22, 'Launchpad.ai blog']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 16 icons, 6.6ms\n",
      "Speed: 3.1ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:58:17,928: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 8.000000 seconds]\n",
      "[2024-12-19 23:58:27,312: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-19 23:58:36,007: INFO: logger: Step 2 | Action: Click | Action Args: [0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 1 icon, 8.9ms\n",
      "Speed: 4.2ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:58:37,767: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-19 23:58:46,301: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 6.000000 seconds]\n",
      "[2024-12-19 23:58:53,286: INFO: logger: Step 3 | Action: Click | Action Args: [3]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 4 icons, 6.7ms\n",
      "Speed: 3.1ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:58:55,044: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 10.000000 seconds]\n",
      "[2024-12-19 23:59:07,294: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 5.000000 seconds]\n",
      "[2024-12-19 23:59:13,215: INFO: logger: Step 4 | Action: Click | Action Args: [7]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 18 icons, 6.9ms\n",
      "Speed: 3.1ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:59:15,016: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 9.000000 seconds]\n",
      "[2024-12-19 23:59:25,116: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 6.000000 seconds]\n",
      "[2024-12-19 23:59:31,734: INFO: logger: Step 1 | Action: Click | Action Args: [8]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 6 icons, 6.6ms\n",
      "Speed: 3.0ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:59:33,269: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-19 23:59:41,202: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 5.000000 seconds]\n",
      "[2024-12-19 23:59:47,395: INFO: logger: Step 1 | Action: Type | Action Args: [12, 'Pydantic']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 14 icons, 7.1ms\n",
      "Speed: 3.8ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 23:59:49,136: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 9.000000 seconds]\n",
      "[2024-12-20 00:00:00,049: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 6.000000 seconds]\n",
      "[2024-12-20 00:00:06,803: INFO: logger: Step 2 | Action: Click | Action Args: [39]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 14 icons, 6.6ms\n",
      "Speed: 3.3ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-20 00:00:08,833: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 8.000000 seconds]\n",
      "[2024-12-20 00:00:19,123: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 6.000000 seconds]\n",
      "[2024-12-20 00:00:28,105: INFO: logger: Step 3 | Action: Click | Action Args: [13]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 21 icons, 7.8ms\n",
      "Speed: 3.3ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-20 00:00:30,793: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-20 00:00:39,156: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-20 00:00:46,993: INFO: logger: Step 4 | Action: Type | Action Args: [1, 'Pydantic']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 6 icons, 6.6ms\n",
      "Speed: 3.3ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-20 00:00:48,521: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-20 00:00:56,759: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 5.000000 seconds]\n",
      "[2024-12-20 00:01:02,480: INFO: logger: Step 1 | Action: Type | Action Args: [22, 'Tesla stock price Apple stock price']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 12 icons, 7.0ms\n",
      "Speed: 3.3ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-20 00:01:04,252: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 9.000000 seconds]\n",
      "[2024-12-20 00:01:14,817: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 6.000000 seconds]\n",
      "[2024-12-20 00:01:21,637: INFO: logger: Step 2 | Action: Click | Action Args: [2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 14 icons, 6.8ms\n",
      "Speed: 3.3ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-20 00:01:23,869: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 8.000000 seconds]\n",
      "[2024-12-20 00:01:34,866: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "[2024-12-20 00:01:43,070: INFO: logger: Step 3 | Action: Answer | Action Args: ['$249.84', '$436.31']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Grab some examples\n",
    "usr_stories = [file_name for file_name in os.listdir(Path(project_root) / \"Examples\")\n",
    "               if file_name.startswith(\"story_\")]\n",
    "usr_stories.sort()\n",
    "examples = []\n",
    "for story in usr_stories:\n",
    "    examples.extend(select_examples(file_path=Path(project_root) / \"Examples\" / story))\n",
    "\n",
    "#Initialize the dictionary to capture the results from each exmaple \n",
    "all_results = []\n",
    "\n",
    "# Test them\n",
    "SAVE_EVERY = 5\n",
    "file_name = \"benchmark_results.json\"\n",
    "for i, example in enumerate(examples):\n",
    "    try:\n",
    "        results = asyncio.run(compare_agent_node(example, web_agent, verbose=False))\n",
    "    except:\n",
    "        continue\n",
    "    all_results.append(results)\n",
    "    if i % 5 == 0:\n",
    "        with open(Path(project_root) / file_name, \"w\") as f:\n",
    "            json.dump(all_results, f, indent=4)\n",
    "            \n",
    "with open(Path(project_root) / file_name, \"w\") as f:\n",
    "    json.dump(all_results, f, indent=4)\n",
    "\n",
    "#  results = {\n",
    "#         \"action_matched\": action_matched,\n",
    "#         \"correct_action\": correct_action,\n",
    "#         \"predicted_action\": end_state['prediction']['action'],\n",
    "#         \"normalized_error\": normalized_error,\n",
    "#         \"time_taken\": end_time - start_time,\n",
    "#         \"target_window_matched\": target_matched,\n",
    "#         \"direction_matched\": direction_matched,\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Found 7 examples\n",
      "INFO: Found 2 examples\n",
      "INFO: Found 11 examples\n",
      "INFO: Found 5 examples\n",
      "INFO: Found 9 examples\n",
      "INFO: Found 4 examples\n",
      "INFO: Found 1 examples\n",
      "INFO: Found 4 examples\n",
      "INFO: Found 3 examples\n"
     ]
    }
   ],
   "source": [
    "usr_stories = [file_name for file_name in os.listdir(Path(project_root) / \"Examples\")\n",
    "               if file_name.startswith(\"story_\")]\n",
    "usr_stories.sort()\n",
    "examples = []\n",
    "for story in usr_stories:\n",
    "    examples.extend(select_examples(file_path=Path(project_root) / \"Examples\" / story))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_json(Path(project_root) / \"benchmark_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action_matched</th>\n",
       "      <th>correct_action</th>\n",
       "      <th>predicted_action</th>\n",
       "      <th>normalized_error</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>target_window_matched</th>\n",
       "      <th>direction_matched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>Click</td>\n",
       "      <td>Click</td>\n",
       "      <td>175.867688</td>\n",
       "      <td>4.233876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>Click</td>\n",
       "      <td>Google</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.996728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>Type</td>\n",
       "      <td>Click</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.171736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>Scroll</td>\n",
       "      <td>Type</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.566147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>Answer</td>\n",
       "      <td>Click</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.734212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   action_matched correct_action predicted_action  normalized_error  \\\n",
       "0            True          Click            Click        175.867688   \n",
       "1           False          Click           Google          0.000000   \n",
       "2           False           Type            Click          0.000000   \n",
       "3           False         Scroll             Type          0.000000   \n",
       "4           False         Answer            Click          0.000000   \n",
       "\n",
       "   time_taken  target_window_matched  direction_matched  \n",
       "0    4.233876                    NaN                NaN  \n",
       "1    3.996728                    NaN                NaN  \n",
       "2    9.171736                    NaN                NaN  \n",
       "3   20.566147                    NaN                NaN  \n",
       "4   21.734212                    NaN                NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries = len(df)\n",
    "df.action_matched.sum() / entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_from_click = np.array(df.normalized_error)[np.logical_and(np.array(df.correct_action) == \"Click\", np.array(df.action_matched))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14285714285714285"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((distance_from_click < 1)) / len(distance_from_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicks = df.loc[df[\"correct_action\"] == \"Click\"]\n",
    "# Google = df.loc[df[\"correct_action\"] == \"Google\"]\n",
    "# Type = df.loc[df[\"correct_action\"] == \"Type\"]\n",
    "# Scroll = df.loc[df[\"correct_action\"] == \"Scroll\"]\n",
    "# Answer = df.loc[df[\"correct_action\"] == \"Answer\"]\n",
    "\n",
    "actions = [\"Click\", \"Type\", \"Scroll\", \"Answer\"]  #  \"Google\",\n",
    "dfs = {action: df.loc[df[\"correct_action\"] == action] for action in actions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click had accuracy 0.7 with entries 20\n",
      "Type had accuracy 0.45454545454545453 with entries 11\n",
      "Scroll had accuracy 0.0 with entries 3\n",
      "Answer had accuracy 0.16666666666666666 with entries 6\n"
     ]
    }
   ],
   "source": [
    "for action, spec_df in dfs.items():\n",
    "    print(action, \"had accuracy\", spec_df.action_matched.sum() / len(spec_df), \"with entries\", len(spec_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
