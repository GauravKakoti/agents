{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Scraper tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import Runnable\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply() # to allow asynchronous calls in a jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class PriceInformation(BaseModel):\n",
    "    \"\"\"Information about a pricing\"\"\"\n",
    "    price: str = Field(..., description=\"The price value as a string (e.g. $19.99)\")\n",
    "    currency: str = Field(..., description=\"The currency symbol or code (e.g. $ or USD)\")\n",
    "    description: str = Field(..., description=\"A brief description of the item or service\")\n",
    "\n",
    "class Prices(BaseModel):\n",
    "    \"\"\"Identifying all pricing information present in the screenshot or text.\"\"\"\n",
    "    prices: List[PriceInformation] = Field(..., description=\"A list of pricing information found on the page\")\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"user\", \n",
    "            [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"\"\"You are a specialized AI who is a part of a multi-agent system tasked with the scraping pricing information from screenshots of websites.\n",
    "                    Below you are given a screenshot of a website. Analyze the image and extract all pricing details.\n",
    "                    Return them as a JSON-formatted string that conforms to the following schema:\n",
    "                    {format_instructions}\n",
    "                    Return only a JSON-formatted string and nothing else.\n",
    "                    If no pricing information is found, return `None`.\"\"\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": \"data:image/png;base64,{img}\"}\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ").partial(format_instructions=parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "import json\n",
    "\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "  \n",
    "class Scraper:\n",
    "    def __init__(self, mm_llm, prompt, save_file : str = \"scraped_data.jsonl\"):\n",
    "        self.mm_llm = mm_llm\n",
    "        self.prompt = prompt\n",
    "        self.parser = parser\n",
    "        self.chain = prompt | mm_llm \n",
    "\n",
    "        self.save_file = save_file\n",
    "\n",
    "        if not os.path.isfile(self.save_file):\n",
    "           # create file\n",
    "           with open(self.save_file, \"w\"):\n",
    "              pass\n",
    "\n",
    "    def run(self, img_path: str):\n",
    "        # TODO(dominic): Currently just playing with images but eventually this needs to take in an AgentState\n",
    "        # TODO(dominic): Investigate if we should use the parser as well to create a pydantic object.\n",
    "        img = encode_image(image_path=img_path)\n",
    "\n",
    "        result = self.chain.invoke({\"img\": img})\n",
    "        # We may need to parse result\n",
    "        with open(self.save_file, \"a\") as f:\n",
    "           json_line = json.dumps(result.content)\n",
    "           f.write(json_line + \"\\n\")\n",
    "\n",
    "        return result\n",
    "\n",
    "        \n",
    "scraper = Scraper(\n",
    "    mm_llm=ChatGroq(model=\"llama-3.2-90b-vision-preview\"),\n",
    "    prompt = scraper_prompt,\n",
    ")\n",
    "result = scraper.run(\"../my_screenshots/lightning_ai_pricing.png\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simplified integration into a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synchronous setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from langchain_core.runnables import RunnableLambda, Runnable\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langchain_groq import ChatGroq\n",
    "from typing import TypedDict, Optional, Union\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    should_scrape: bool\n",
    "    image_path: Optional[str]  # Image path can be None initially\n",
    "    prediction: Optional[dict]  # Holds the agent's action decision\n",
    "    observation: Optional[Union[str, dict]]  # The result from the Scraper or any output\n",
    "\n",
    "\n",
    "# Step 1: Define a simple decision agent\n",
    "class RandomDecisionAgent(Runnable):\n",
    "    def run(self, state: AgentState):\n",
    "        # Randomly decide if the image should be scraped\n",
    "        state['should_scrape'] = random.choice([True, False])\n",
    "        if state['should_scrape']:\n",
    "            state['prediction'] = {\"action\": \"Scraper\"}\n",
    "        else:\n",
    "            state['prediction'] = {\"action\": \"END\"}\n",
    "        return state\n",
    "\n",
    "    def invoke(self, state: AgentState, *args, **kwargs):\n",
    "        # Directly call the run method\n",
    "        return self.run(state)\n",
    "\n",
    "\n",
    "# Instantiate the decision agent\n",
    "decision_agent = RandomDecisionAgent()\n",
    "\n",
    "# Step 2: Define the Scraper class that uses a multimodal model chain\n",
    "class Scraper(Runnable):\n",
    "    def __init__(self, mm_llm, prompt, save_file: str = \"scraped_data.jsonl\"):\n",
    "        super().__init__()\n",
    "        self.chain = prompt | mm_llm\n",
    "        self.save_file = save_file\n",
    "\n",
    "        if not os.path.isfile(self.save_file):\n",
    "            with open(self.save_file, \"w\"):\n",
    "                pass\n",
    "\n",
    "    def run(self, state: AgentState):\n",
    "        img_path = state.get('image_path')\n",
    "        if not img_path:\n",
    "            raise ValueError(\"Image path is missing from the state.\")\n",
    "        \n",
    "        # Encode the image (use your existing encode_image function)\n",
    "        img = encode_image(img_path)\n",
    "        \n",
    "        # Run the multimodal LLM chain\n",
    "        result = self.chain.invoke({\"img\": img})\n",
    "        state['observation'] = result\n",
    "\n",
    "        # save result to save_path\n",
    "        with open(self.save_file, \"a\") as f:\n",
    "           json_line = json.dumps(result.content)\n",
    "           f.write(json_line + \"\\n\")\n",
    "           \n",
    "        return state\n",
    "\n",
    "    def invoke(self, state: AgentState, *args, **kwargs):\n",
    "        # Directly call the run method\n",
    "        return self.run(state)\n",
    "\n",
    "\n",
    "# Step 3: Instantiate the LLM and Scraper tool\n",
    "llm = ChatGroq(model=\"llama-3.2-90b-vision-preview\", max_tokens=4096)\n",
    "scraper_tool = Scraper(mm_llm=llm, prompt=scraper_prompt)  # Replace `scraper_prmopt` with your actual prompt\n",
    "\n",
    "# Step 4: Build the LangGraph\n",
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "# Add the decision agent node\n",
    "graph_builder.add_node(\"agent\", decision_agent)\n",
    "graph_builder.add_edge(START, \"agent\")\n",
    "\n",
    "# Add the Scraper node\n",
    "graph_builder.add_node(\"Scraper\", scraper_tool)\n",
    "graph_builder.add_edge(\"Scraper\", END)\n",
    "\n",
    "# Define the function for conditional routing based on `should_scrape`\n",
    "def select_tool(state: AgentState):\n",
    "    action = state[\"prediction\"][\"action\"]\n",
    "    if action == \"END\":\n",
    "        return END\n",
    "    return action  # This will route to \"Scraper\" or \"END\"\n",
    "\n",
    "graph_builder.add_conditional_edges(\"agent\", select_tool)\n",
    "\n",
    "# Compile the graph\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# Step 5: Run the graph with an initial state\n",
    "initial_state = AgentState(image_path=\"../my_screenshots/lightning_ai_pricing.png\")\n",
    "\n",
    "# Execute the graph synchronously\n",
    "result = graph.invoke(initial_state)\n",
    "\n",
    "# Print the final observation\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_graph_updates(initial_state: AgentState):\n",
    "    # Stream the graph updates with the given initial state\n",
    "    for event in graph.stream(initial_state):\n",
    "        # Iterate over the event outputs and print them\n",
    "        for node_name, output in event.items():\n",
    "            if \"observation\" in output:\n",
    "                print(f\"{node_name} output: {output['observation']}\")\n",
    "            else:\n",
    "                print(f\"{node_name} event: {output}\")\n",
    "\n",
    "stream_graph_updates(initial_state=initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Asynchronous setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from langchain_core.runnables import RunnableLambda, Runnable\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langchain_groq import ChatGroq\n",
    "import asyncio\n",
    "import aiofiles\n",
    "\n",
    "from typing import TypedDict, Optional, Union\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    should_scrape: bool\n",
    "    image_path: Optional[str] \n",
    "    prediction: Optional[dict]  # Holds the agent's action decision\n",
    "    observation: Optional[Union[str, dict]]  # The result from the Scraper or any tool more generally\n",
    "\n",
    "\n",
    "# Step 1: Define a simple decision agent\n",
    "class RandomDecisionAgent(Runnable):\n",
    "    \"\"\"Randomly decides if we should scrape, to simulate an Agent\"\"\"\n",
    "    async def run(self, state: AgentState):\n",
    "        # Randomly decide if the image should be scraped\n",
    "        state['should_scrape'] = random.choice([True, False])\n",
    "        if state['should_scrape']:\n",
    "            state['prediction'] = {\"action\": \"Scraper\"}\n",
    "        else:\n",
    "            state['prediction'] = {\"action\": \"END\"}\n",
    "        return state\n",
    "\n",
    "    async def ainvoke(self, state: AgentState, *args, **kwargs):\n",
    "        \n",
    "        return await self.run(state)\n",
    "\n",
    "    def invoke(self, state: AgentState, *args, **kwargs):\n",
    "        \n",
    "        return asyncio.create_task(self.run(state))\n",
    "\n",
    "decision_agent = RandomDecisionAgent()\n",
    "\n",
    "# Step 2: Define the Scraper class that uses a multimodal model chain\n",
    "# This can't be a chain built out of LCEL since we need to encode the image first. \n",
    "# ideally in our actual use case, one of the parameters of AgentState will be the encoded screenshot\n",
    "class Scraper(Runnable):\n",
    "    def __init__(self, mm_llm, prompt, save_file: str = \"scraped_data.jsonl\"):\n",
    "        super().__init__()\n",
    "        self.chain = prompt | mm_llm\n",
    "        self.save_file = save_file\n",
    "\n",
    "        if not os.path.isfile(self.save_file):\n",
    "            with open(self.save_file, \"w\"):\n",
    "                pass\n",
    "\n",
    "    async def run(self, state: AgentState):\n",
    "        img_path = state.get('image_path')\n",
    "        if not img_path:\n",
    "            raise ValueError(\"Image path is missing from the state.\")\n",
    "        \n",
    "        print(f\"Encoding image...\")\n",
    "        img = encode_image(img_path)\n",
    "        \n",
    "        print(f\"Passing image to chain...\")\n",
    "        result = await self.chain.ainvoke({\"img\": img})        \n",
    "        state['observation'] = result\n",
    "\n",
    "        async with aiofiles.open(self.save_file, \"a\") as f:\n",
    "            json_line = json.dumps(result.content)\n",
    "            await f.write(json_line + \"\\n\")\n",
    "\n",
    "        return state\n",
    "\n",
    "    async def ainvoke(self, state: AgentState, *args, **kwargs):\n",
    "        return await self.run(state)\n",
    "\n",
    "    def invoke(self, state: AgentState, *args, **kwargs):\n",
    "        # TODO(dominic) probably not best practice to do this...\n",
    "        return asyncio.create_task(self.run(state))\n",
    "\n",
    "\n",
    "# Step 3: Instantiate the LLM and Scraper tool\n",
    "llm = ChatGroq(model=\"llama-3.2-90b-vision-preview\", max_tokens=4096)\n",
    "scraper_tool = Scraper(mm_llm=llm, prompt=scraper_prompt)  # Replace `scraper_prmopt` with your actual prompt\n",
    "\n",
    "# Step 4: Build the LangGraph\n",
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "# Add the decision agent node\n",
    "graph_builder.add_node(\"agent\", decision_agent)\n",
    "graph_builder.add_edge(START, \"agent\")\n",
    "\n",
    "# Add the Scraper node\n",
    "graph_builder.add_node(\"Scraper\", scraper_tool)\n",
    "graph_builder.add_edge(\"Scraper\", END)\n",
    "\n",
    "# Define the function for conditional routing based on `should_scrape`\n",
    "def select_tool(state: AgentState):\n",
    "    action = state[\"prediction\"][\"action\"]\n",
    "    if action == \"END\":\n",
    "        return END\n",
    "    return action  # This will route to \"Scraper\" or \"END\"\n",
    "\n",
    "graph_builder.add_conditional_edges(\"agent\", select_tool)\n",
    "\n",
    "# Compile the graph\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Run the graph with an initial state using astream()\n",
    "initial_state = AgentState(image_path=\"../my_screenshots/lightning_ai_pricing.png\")\n",
    "async def run_graph_and_collect_result(initial_state: AgentState):\n",
    "    event_stream = graph.astream(initial_state)\n",
    "    final_state = None\n",
    "\n",
    "    async for event in event_stream:\n",
    "        # Process each event (e.g., for debugging, step logging, etc.)\n",
    "        # Here, you could add print statements or store intermediate results.\n",
    "        print(\"Intermediate event:\", event)\n",
    "        print(\"Intermediate observation:\", event['Scraper']['observation'].content if 'Scraper' in event else \"\")\n",
    "\n",
    "        # Collect the final state once streaming is complete\n",
    "        final_state = event\n",
    "\n",
    "    return final_state\n",
    "\n",
    "# Run the async function to execute the graph\n",
    "result = await run_graph_and_collect_result(initial_state)\n",
    "\n",
    "# Print the final observation\n",
    "if result:\n",
    "    print(result['Scraper']['observation'].content if \"Scraper\" in result else \"No scraping\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting JSON string from result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die folge code ist von https://python.langchain.com/docs/how_to/structured_output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class PriceInformation(BaseModel):\n",
    "    \"\"\"Information about a pricing\"\"\"\n",
    "    price: str = Field(..., description=\"The price value as a string (e.g. $19.99)\")\n",
    "    currency: str = Field(..., description=\"The currency symbol or code (e.g. $ or USD)\")\n",
    "    description: str = Field(..., description=\"A brief description of the item or service\")\n",
    "\n",
    "class Prices(BaseModel):\n",
    "    \"\"\"Identifying all pricing information present in the screenshot or text.\"\"\"\n",
    "    prices: List[PriceInformation] = Field(..., description=\"A list of pricing information found on the page\")\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Prices)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"user\", \n",
    "            [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"\"\"You are a specialized AI who is a part of a multi-agent system tasked with the scraping pricing information from screenshots of websites.\n",
    "                    Below you are given a screenshot of a website. Analyze the image and extract all pricing details.\n",
    "                    Return them as a JSON-formatted string that conforms to the following schema:\n",
    "                    {format_instructions}\n",
    "                    Return only a JSON-formatted string and nothing else.\n",
    "                    If no pricing information is found, return `None`.\"\"\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": \"data:image/png;base64,{img}\"}\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ").partial(format_instructions=parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scraper_prompt.messages[0].prompt[0].template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "import json\n",
    "\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "  \n",
    "class Scraper:\n",
    "    def __init__(self, mm_llm, prompt, save_file: str = \"scraped_data.jsonl\"):\n",
    "        self.mm_llm = mm_llm\n",
    "        self.prompt = prompt\n",
    "        self.chain = prompt | mm_llm\n",
    "\n",
    "        self.save_file = save_file\n",
    "\n",
    "        if not os.path.isfile(self.save_file):\n",
    "           # create file\n",
    "           with open(self.save_file, \"w\"):\n",
    "              pass\n",
    "\n",
    "    def run(self, img_path: str):\n",
    "        # TODO(dominic): Currently just playing with images but eventually this needs to take in an AgentState\n",
    "\n",
    "        img = encode_image(image_path=img_path)\n",
    "\n",
    "        result = self.chain.invoke({\"img\": img})\n",
    "        # We may need to parse result\n",
    "        with open(self.save_file, \"a\") as f:\n",
    "           json_line = json.dumps(result.content)\n",
    "           f.write(json_line + \"\\n\")\n",
    "\n",
    "        return result\n",
    "\n",
    "        \n",
    "scraper = Scraper(\n",
    "    mm_llm=ChatGroq(model=\"llama-3.2-90b-vision-preview\"),\n",
    "    prompt = scraper_prompt\n",
    ")\n",
    "result = scraper.run(\"../my_screenshots/lightning_ai_pricing.png\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"The name of the person\")\n",
    "    height_in_meters: float = Field(\n",
    "        ..., description=\"The height of the person expressed in meters.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class People(BaseModel):\n",
    "    \"\"\"Identifying information about all people in a text.\"\"\"\n",
    "\n",
    "    people: List[Person]\n",
    "\n",
    "\n",
    "# Set up a parser\n",
    "parser = PydanticOutputParser(pydantic_object=People)\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\",\n",
    "        ),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ").partial(format_instructions=parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Anna is 23 years old and she is 6 feet tall\"\n",
    "\n",
    "print(prompt.invoke(query).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | parser\n",
    "\n",
    "chain.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fellowship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
