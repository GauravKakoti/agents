{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://langchain-ai.github.io/langgraph/tutorials/web-navigation/web_voyager/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "USE_GROQ = True  # False uses OpenAI\n",
    "\n",
    "os.getenv(\"GROQ_CLOUD_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presuming your directory structure is the default git one, this is set up to run in the main web-agent folder, so cd up one:\n",
    "if \"src\" not in os.listdir():\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply() # to allow asynchronous calls in a jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage, SystemMessage\n",
    "from playwright.async_api import Page\n",
    "\n",
    "class BBox(TypedDict):\n",
    "    x: float\n",
    "    y: float\n",
    "    text: str\n",
    "    type: str\n",
    "    ariaLabel: str\n",
    "\n",
    "class Prediction(TypedDict):\n",
    "    action: str\n",
    "    args: Optional[List[str]]\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    page: Page\n",
    "    input: str\n",
    "    img: str #b64 encoded screenshot\n",
    "    bboxes: List[BBox]\n",
    "    prediction: Prediction # agent's output\n",
    "    scratchpad: List[BaseMessage] # A system message or messages containing the intermediate steps\n",
    "    observation: str # the most recent response from a tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There will be 6 tools:\n",
    "\n",
    "1. Click (at labeled box)\n",
    "2. Type\n",
    "3. Scroll\n",
    "4. Wait\n",
    "5. Go Back\n",
    "6. Go to search engine (Google)\n",
    "\n",
    "we define those now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def click(state: AgentState):\n",
    "    # - Click [Numerical_label]\n",
    "    page = state['page']\n",
    "    click_args = state['prediction']['args']\n",
    "    if click_args is None or len(click_args) != 1:\n",
    "        return f\"Failed to click bounding box labeled as number {click_args}\"\n",
    "    bbox_id = click_args[0]\n",
    "    bbox_id = int(bbox_id)\n",
    "    try:\n",
    "        bbox = state['bboxes'][bbox_id]\n",
    "    except Exception:\n",
    "        return f\"Error: no bbox for : {bbox_id}\"\n",
    "    \n",
    "    x, y = bbox['x'], bbox['y']\n",
    "    await page.mouse.click(x,y)\n",
    "    # TODO: In the paper, they automatically parse any downloaded PDFs\n",
    "    # We could add something similar here as well and generally\n",
    "    # improve response format.\n",
    "    return f\"Clicked {bbox_id}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def type_text(state: AgentState):\n",
    "    page = state['page']\n",
    "    type_args = state['prediction']['args']\n",
    "    if type_args is None or len(type_args) != 2:\n",
    "        return f\"Failed to type in element from bounding box labeled as number {type_args}\"\n",
    "    bbox_id = type_args[0]\n",
    "    bbox_id = int(bbox_id)\n",
    "    bbox = state['bboxes'][bbox_id]\n",
    "    x, y = bbox['x'], bbox['y']\n",
    "    text_content = type_args[1]\n",
    "    await page.mouse.click(x, y)\n",
    "\n",
    "    # check if MacOS\n",
    "    select_all = \"Meta+A\" if platform.system() == \"Darwin\" else \"Control+A\"\n",
    "    await page.keyboard.press(select_all)\n",
    "    await page.keyboard.press(\"Backspace\")\n",
    "    await page.keyboard.type(text_content)\n",
    "    await page.keyboard.press(\"Enter\")\n",
    "    return f\"Typed {text_content} and submitted\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scroll(state: AgentState):\n",
    "    page = state['page']\n",
    "    scroll_args = state['prediction']['args']\n",
    "    if scroll_args is None or len(scroll_args) != 2:\n",
    "        return \"Failed to scroll due to incorrect arguments\"\n",
    "    \n",
    "    target, direction = scroll_args\n",
    "\n",
    "    if target.upper() == 'WINDOW':\n",
    "        # Not sure of the best value for this...\n",
    "        scroll_amount = 500\n",
    "        scroll_direction = (\n",
    "            -scroll_amount if direction.lower() == 'up' else scroll_amount\n",
    "        )\n",
    "        await page.evaluate(f\"window.scrollBy(0, {scroll_direction})\")\n",
    "    else:\n",
    "        # scrolling within a specific element\n",
    "        scroll_amount=200\n",
    "        target_id = int(target)\n",
    "        bbox = state['bboxes'][target_id]\n",
    "        x, y = bbox['x'], bbox['y']\n",
    "        scroll_direction = (\n",
    "            -scroll_amount if direction.lower() == 'up' else scroll_amount\n",
    "        )\n",
    "        await page.mouse.move(x, y)\n",
    "        await page.mouse.wheel(0, scroll_direction)\n",
    "    return f\"Scrolled {direction} in {'window' if target.upper() == 'WINDOW' else 'element'}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def wait(state: AgentState):\n",
    "    sleep_time = 5\n",
    "    await asyncio.sleep(sleep_time)\n",
    "    return f\"Waited for {sleep_time}s\"\n",
    "\n",
    "async def go_back(state: AgentState):\n",
    "    page = state['page']\n",
    "    await page.go_back()\n",
    "    return f\"Navigated back to page to {page.url}\"\n",
    "\n",
    "async def to_google(state: AgentState):\n",
    "    page = state['page']\n",
    "    await page.goto(\"https://www.google.com/\")\n",
    "    return \"Navigated to google.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agend is driven by a multimodal model and decided the action to take for each step. It is composed of a few runnable objects:\n",
    "1. A `mark_page` function to annotate the current page with bounding boxes. \n",
    "2. A prompt to hold the user question, annotated image, and agent scratchpad\n",
    "3. GPT-4V to decide the next steps\n",
    "4. Parsing logic to extract the action\n",
    "\n",
    "We implement this below. We start with the annotation step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Browser annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from langchain_core.runnables import chain as chain_decorator\n",
    "\n",
    "# some javascript we will run on each step to take a screenshot of the page, select the elements to annotate, and add bounding boxes\n",
    "with open(\"src/mark_page.js\") as f:\n",
    "    mark_page_script = f.read()\n",
    "\n",
    "@chain_decorator\n",
    "async def mark_page(page):\n",
    "    await page.evaluate(mark_page_script)\n",
    "    for _ in range(10):\n",
    "        try:\n",
    "            bboxes = await page.evaluate(\"markPage()\")\n",
    "            break\n",
    "        except Exception:\n",
    "            # may be loading\n",
    "            asyncio.sleep(3)\n",
    "    screenshot = await page.screenshot()\n",
    "    # Ensure the bboxes don't follow us around\n",
    "    await page.evaluate(\"unmarkPage()\")\n",
    "    return {\n",
    "        \"img\": base64.b64encode(screenshot).decode('utf-8'),\n",
    "        \"bboxes\": bboxes\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "import re\n",
    "\n",
    "async def annotate(state):\n",
    "    marked_page = await mark_page.with_retry().ainvoke(state[\"page\"])\n",
    "    return {**state, **marked_page}\n",
    "\n",
    "\n",
    "def format_descriptions(state):\n",
    "    labels = []\n",
    "    for i, bbox in enumerate(state[\"bboxes\"]):\n",
    "        text = bbox.get(\"ariaLabel\") or \"\"\n",
    "        if not text.strip():\n",
    "            text = bbox[\"text\"]\n",
    "        el_type = bbox.get(\"type\")\n",
    "        labels.append(f'{i} (<{el_type}/>): \"{text}\"')\n",
    "    bbox_descriptions = \"\\nValid Bounding Boxes:\\n\" + \"\\n\".join(labels)\n",
    "    return {**state, \"bbox_descriptions\": bbox_descriptions}\n",
    "\n",
    "\n",
    "def parse(text: str) -> dict:\n",
    "    # set up regex for prefixes for our two points of interest\n",
    "    thought_prefix = r\"(?i)thoughts*:*\\** *-* *\\n*\"\n",
    "    action_prefix = r\"(?i)\\n *\\**action:*\\** *-* *\\n*\"  # Just combining all prefixes seen so far\n",
    "\n",
    "    # Extract the thought\n",
    "    text_by_thought = re.split(thought_prefix, text, 1)\n",
    "    if len(text_by_thought) > 1:\n",
    "        put_back_in_action = \" action \" # In case the thoughts included the word action and we accidentally cut it out\n",
    "        # The logic below is that we want everything from \"Thought:\" until the last \"Action:\", so we split by \"Action:\" and take every block\n",
    "        # but the last, but since the word \"action\" might be in the thoughts, everywhere we split we add back in the word \"action\", and cut it \n",
    "        # back off at the end\n",
    "        thought = \"\".join(phrase + put_back_in_action for phrase in re.split(action_prefix, text_by_thought[1])[:-1])[:-len(put_back_in_action)].strip()\n",
    "    else:\n",
    "        thought = \"cannot find the thought\"\n",
    "\n",
    "    # action_prefix = \"Action: \"\n",
    "    # if not all_text[-1].startswith(action_prefix):\n",
    "    text_by_action = re.split(action_prefix, text)\n",
    "    if len(text_by_action) < 2:\n",
    "        return {\"action\": \"retry\", \"args\": f\"Could not parse LLM Action in: {text.strip()},\\nWe will mark this as the thought\", \"thought\": text}\n",
    "    action_block = text_by_action[-1].strip()\n",
    "    split_output = action_block.split(\" \", 1)\n",
    "\n",
    "    # Extract the parameters for the function, and what function to use\n",
    "    if len(split_output) == 1:\n",
    "        action, action_input = split_output[0], None # If there's no parameters, just set the action\n",
    "    else:\n",
    "        action, action_input = split_output\n",
    "    action = action.strip()\n",
    "    if action_input is not None:\n",
    "        action_input = [\n",
    "            inp.strip(\"\\\"'[]\") for inp in re.split(\";[\\t ]*|,[\\t ]*|\\t[\\t ]*|  *\\\"|  *'\", action_input.strip())  # Cut the parameters string into individual parameters\n",
    "        ]\n",
    "        if len(action_input) == 1 and len(action_input[0].split(\" \")) == 2:\n",
    "            action_input = [inp.strip(\"\\\"'[]\") for inp in action_input[0].split(\" \")]\n",
    "    return {\"action\": action, \"args\": action_input, \"thought\": thought}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_dict = parse(\"\"\"\n",
    "                    I'm not going to engage in this topic matter\"\"\")\n",
    "print(repr(parsed_dict[\"args\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build the scraper tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "import asyncio\n",
    "import aiofiles\n",
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.runnables import RunnableLambda, Runnable\n",
    "\n",
    "from src.custom_types import AgentState\n",
    "\n",
    "\n",
    "class RateInformation(BaseModel):\n",
    "    \"\"\"Information about a pricing\"\"\"\n",
    "    rate: str = Field(..., description=\"The interest rate value as a string (e.g. %2.37)\")\n",
    "    description: str = Field(..., description=\"A brief description of the financial instrument\")\n",
    "    organization: str = Field(..., description=\"A brief description of the lender or the financial provider\")\n",
    "\n",
    "class Rates(BaseModel):\n",
    "    \"\"\"Identifying all pricing information present in the screenshot or text.\"\"\"\n",
    "    prices: List[RateInformation] = Field(..., description=\"A list of pricing information found on the page\")\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Rates)\n",
    "\n",
    "SCRAPER_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"user\", \n",
    "            [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"\"\"You are a specialized AI who is a part of a multi-agent system tasked with the scraping interest rate and other financial information from screenshots of websites.\n",
    "                    Below you are given a screenshot of a website. Analyze the image and extract all interest rate or other financial details.\n",
    "                    Return them as a JSON-formatted string that conforms to the following schema:\n",
    "                    {format_instructions}\n",
    "                    Return only a JSON-formatted string and nothing else.\n",
    "                    If no pricing information is found, return `None`.\"\"\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": \"data:image/png;base64,{img}\"}\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ").partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "class Scraper(Runnable):\n",
    "    def __init__(self, mm_llm, prompt, save_file: str = \"scraped_data.jsonl\"):\n",
    "        super().__init__()\n",
    "        self.chain = prompt | mm_llm\n",
    "        self.save_file = save_file\n",
    "\n",
    "        if not os.path.isfile(self.save_file):\n",
    "            with open(self.save_file, \"w\"):\n",
    "                pass\n",
    "\n",
    "    async def run(self, state: AgentState):\n",
    "        img_data = state.get('img')\n",
    "        if not img_data:\n",
    "            raise ValueError(\"Image path is missing from the state.\")\n",
    "        \n",
    "        \n",
    "        print(f\"Passing image to chain...\")\n",
    "        result = await self.chain.ainvoke({\"img\": img_data}) ;        \n",
    "        state['observation'] = result.content # TODO(dominic): is this the best way to do this? Or should we modify how we record observations...\n",
    "\n",
    "        async with aiofiles.open(self.save_file, \"a\") as f:\n",
    "            json_line = json.dumps(result.content)\n",
    "            await f.write(json_line + \"\\n\")\n",
    "\n",
    "        return state\n",
    "\n",
    "    async def ainvoke(self, state: AgentState, *args, **kwargs):\n",
    "        return await self.run(state)\n",
    "\n",
    "    def invoke(self, state: AgentState, *args, **kwargs):\n",
    "        # TODO(dominic) probably not best practice to do this...\n",
    "        return asyncio.create_task(self.run(state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"\"\"Imagine you are a robot browsing the web, just like humans. Now you need to complete a task. In each iteration, you will receive an Observation that includes a screenshot of a webpage and some texts. This screenshot will\n",
    "feature Numerical Labels placed in the TOP LEFT corner of each Web Element. Carefully analyze the visual\n",
    "information to identify the Numerical Label corresponding to the Web Element that requires interaction, then follow\n",
    "the guidelines and choose one of the following actions:\n",
    "\n",
    "1. Click a Web Element.\n",
    "2. Delete existing content in a textbox and then type content.\n",
    "3. Scroll up or down.\n",
    "4. Wait \n",
    "5. Go back\n",
    "6. Scrape\n",
    "7. Return to google to start over.\n",
    "8. Respond with the final answer\n",
    "\n",
    "Correspondingly, Action should STRICTLY follow the format:\n",
    "\n",
    "- Click [Numerical_Label] \n",
    "- Type [Numerical_Label]; [Content] \n",
    "- Scroll [Numerical_Label or WINDOW]; [up or down] \n",
    "- Wait \n",
    "- GoBack\n",
    "- Scrape\n",
    "- Google\n",
    "- ANSWER; [content]\n",
    "\n",
    "Key Guidelines You MUST follow:\n",
    "\n",
    "* Action guidelines *\n",
    "1) Execute only one action per iteration.\n",
    "2) When clicking or typing, ensure to select the correct bounding box.\n",
    "3) Numeric labels lie in the top-left corner of their corresponding bounding boxes and are colored the same.\n",
    "\n",
    "* Web Browsing Guidelines *\n",
    "1) Don't interact with useless web elements like Login, Sign-in, donation that appear in Webpages\n",
    "2) Select strategically to minimize time wasted.\n",
    "\n",
    "Your reply should strictly follow the format:\n",
    "\n",
    "Thought: {{Your brief thoughts (briefly summarize the info that will help ANSWER)}}\n",
    "Action: {{One Action format you choose}}\n",
    "Then the User will provide:\n",
    "Observation: {{A labeled screenshot Given by User}}\n",
    "\"\"\"),\n",
    "    MessagesPlaceholder(\"scratchpad\", optional=True),\n",
    "        (\n",
    "            \"user\",\n",
    "            [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": \"data:image/jpeg;base64,{img}\"},\n",
    "                },\n",
    "                {\n",
    "                    'type': 'text',\n",
    "                    'text': \"{bbox_descriptions}\"\n",
    "                },\n",
    "                {\n",
    "                    'type': 'text',\n",
    "                    'text': \"{input}\"\n",
    "                }\n",
    "                \n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import Logger\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "def logger(text):\n",
    "    f = open(\"log.txt\", \"w\")\n",
    "    f.write(text)\n",
    "    f.close()\n",
    "\n",
    "class Print_interrupter(ChatGroq):\n",
    "    def invoke(self, *args, **kwargs):\n",
    "        logger(\"\".join([str(arg) for arg in args]))\n",
    "        return super().invoke(*args, **kwargs)\n",
    "    def ainvoke(self, *args, **kwargs):\n",
    "        logger(\"\".join([str(arg) for arg in args]))\n",
    "        return super().ainvoke(*args, **kwargs)\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        logger(\"\".join([str(arg) for arg in args]))\n",
    "        return super().__call__(*args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import Runnable\n",
    "\n",
    "# Define a custom logging step to print the prompt\n",
    "class PrintRunnable(Runnable):\n",
    "    def invoke(self, input, config, **kwargs):\n",
    "        print(\"Formatted prompt before sending to LLM:\")\n",
    "        print(input)\n",
    "        return input \n",
    "    \n",
    "    async def ainvoke(self, input, config, **kwargs):\n",
    "        print(\"Formatted prompt before sending to LLM:\")\n",
    "        print(input)  # Print the formatted input to check\n",
    "        return input  # Pass the input to the next step in the pipeline\n",
    "    \n",
    "def print_llm_output(input):\n",
    "    print(input)\n",
    "    return input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "if USE_GROQ:\n",
    "    llm = ChatGroq(model=\"llama-3.2-90b-vision-preview\", max_tokens=4096)\n",
    "else:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", max_tokens=4096)\n",
    "\n",
    "agent = annotate | RunnablePassthrough.assign(\n",
    "    prediction=format_descriptions | prompt | llm | StrOutputParser() | parse\n",
    ")\n",
    "scraper_tool = Scraper(mm_llm=llm, prompt=SCRAPER_PROMPT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "def update_scratchpad(state: AgentState):\n",
    "    \"\"\"After a tool is invoked, we want to update\n",
    "    the scratchpad so the agent is aware of its previous steps\"\"\"\n",
    "    old = state.get(\"scratchpad\")\n",
    "    if old:\n",
    "        txt = old[0].content\n",
    "        last_line = txt.rsplit(\"\\n\", 1)[-1]\n",
    "        step = int(re.match(r\"\\d+\", last_line).group()) + 1\n",
    "    else:\n",
    "        txt = \"Previous action observations:\\n\"\n",
    "        step = 1\n",
    "    txt += f\"\\n{step}. {state['observation']}\"\n",
    "\n",
    "    return {**state, \"scratchpad\": [HumanMessage(content=txt)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nolwo we can compose the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"agent\", agent)\n",
    "graph_builder.add_edge(START, \"agent\") # START -> agent\n",
    "\n",
    "graph_builder.add_node(\"update_scratchpad\", update_scratchpad)\n",
    "graph_builder.add_edge(\"update_scratchpad\", \"agent\")\n",
    "\n",
    "tools = {\n",
    "    \"Click\": click,\n",
    "    \"Type\": type_text,\n",
    "    \"Scroll\": scroll,\n",
    "    \"Wait\": wait,\n",
    "    \"GoBack\": go_back,\n",
    "    \"Google\": to_google,\n",
    "}\n",
    "\n",
    "\n",
    "for node_name, tool in tools.items():\n",
    "    graph_builder.add_node(\n",
    "        node_name,\n",
    "        # The lambda ensures the function's string output is mapped to the \"observation\"\n",
    "        # key in the AgentState\n",
    "        RunnableLambda(tool) | (lambda observation: {\"observation\": observation}),\n",
    "    )\n",
    "    # Always return to the agent (by means of the update-scratchpad node)\n",
    "    graph_builder.add_edge(node_name, \"update_scratchpad\")\n",
    "\n",
    "# Add in the scraper\n",
    "graph_builder.add_node(\"Scrape\", scraper_tool)\n",
    "graph_builder.add_edge(\"Scrape\", \"update_scratchpad\")\n",
    "\n",
    "\n",
    "def select_tool(state: AgentState):\n",
    "    # Any time the agent completes, this function\n",
    "    # is called to route the output to a tool or\n",
    "    # to the end user.\n",
    "    action = state[\"prediction\"][\"action\"]\n",
    "    if action.startswith(\"ANSWER\"):\n",
    "        return END\n",
    "    if action == \"retry\":\n",
    "        return \"agent\"\n",
    "    return action\n",
    "\n",
    "\n",
    "graph_builder.add_conditional_edges(\"agent\", select_tool)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from playwright.async_api import async_playwright\n",
    "import langchain\n",
    "\n",
    "langchain.debug = False\n",
    "\n",
    "browser = await async_playwright().start()\n",
    "# We will set headless=False so we can watch the agent navigate the web.\n",
    "browser = await browser.chromium.launch(headless=False, args=None)\n",
    "page = await browser.new_page()\n",
    "_ = await page.goto(\"https://www.google.com/\")\n",
    "\n",
    "# initial_state = {\n",
    "#     \"page\": page,\n",
    "#     \"input\": \"Please find the best mortgage rate available to me using bankrate.com. My zip code is 90210 and the purchase price is $400,000 with a down payment of $85,000. My credit score is 800.\",\n",
    "#     \"scratchpad\": [],\n",
    "# }\n",
    "\n",
    "# result = await agent.ainvoke(initial_state)\n",
    "\n",
    "\n",
    "async def call_agent(question: str, page, max_steps: int = 150):\n",
    "    event_stream = graph.astream(\n",
    "        {\n",
    "            \"page\": page,\n",
    "            \"input\": question,\n",
    "            \"scratchpad\": [],\n",
    "        },\n",
    "        {\n",
    "            \"recursion_limit\": max_steps,\n",
    "        },\n",
    "    )\n",
    "    final_answer = None\n",
    "    steps = []\n",
    "    async for event in event_stream:\n",
    "        # We'll display an event stream here\n",
    "        if \"agent\" not in event:\n",
    "            continue\n",
    "        pred = event[\"agent\"].get(\"prediction\") or {}\n",
    "        print(pred)\n",
    "        action = pred.get(\"action\")\n",
    "        action_input = pred.get(\"args\")\n",
    "        display.clear_output(wait=False)\n",
    "        steps.append(f\"{len(steps) + 1}. {action}: {action_input}\")\n",
    "        print(\"\\n\".join(steps))\n",
    "        display.display(display.Image(base64.b64decode(event[\"agent\"][\"img\"])))\n",
    "        if \"ANSWER\" in action:\n",
    "            final_answer = action_input[0]\n",
    "            break\n",
    "    return final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await call_agent(\"What is the weather in London?\", page)\n",
    "print(f\"Final response: {res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fellowship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
